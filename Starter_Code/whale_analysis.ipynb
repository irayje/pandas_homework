{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  A Whale off the Port(folio)\n",
    "\n",
    " In this assignment, you'll get to use what you've learned this week to evaluate the performance among various algorithmic, hedge, and mutual fund portfolios and compare them against the S&P 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "In this section, you will need to read the CSV files into DataFrames and perform any necessary data cleaning steps. After cleaning, combine all DataFrames into a single DataFrame.\n",
    "\n",
    "Files:\n",
    "1. whale_returns.csv\n",
    "2. algo_returns.csv\n",
    "3. sp500_history.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whale Returns\n",
    "\n",
    "Read the Whale Portfolio daily returns and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOROS FUND MANAGEMENT LLC</th>\n",
       "      <th>PAULSON &amp; CO.INC.</th>\n",
       "      <th>TIGER GLOBAL MANAGEMENT LLC</th>\n",
       "      <th>BERKSHIRE HATHAWAY INC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-03-03</td>\n",
       "      <td>-0.001266</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>-0.006569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-03-04</td>\n",
       "      <td>0.002230</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>-0.002534</td>\n",
       "      <td>0.004213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-03-05</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.006726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-03-06</td>\n",
       "      <td>-0.007905</td>\n",
       "      <td>-0.003574</td>\n",
       "      <td>-0.008481</td>\n",
       "      <td>-0.013098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SOROS FUND MANAGEMENT LLC  PAULSON & CO.INC.   \\\n",
       "Date                                                        \n",
       "2015-03-02                        NaN                 NaN   \n",
       "2015-03-03                  -0.001266           -0.004981   \n",
       "2015-03-04                   0.002230            0.003241   \n",
       "2015-03-05                   0.004016            0.004076   \n",
       "2015-03-06                  -0.007905           -0.003574   \n",
       "\n",
       "            TIGER GLOBAL MANAGEMENT LLC  BERKSHIRE HATHAWAY INC  \n",
       "Date                                                             \n",
       "2015-03-02                          NaN                     NaN  \n",
       "2015-03-03                    -0.000496               -0.006569  \n",
       "2015-03-04                    -0.002534                0.004213  \n",
       "2015-03-05                     0.002355                0.006726  \n",
       "2015-03-06                    -0.008481               -0.013098  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading whale returns\n",
    "whale_returns_csv = pd.read_csv(\"../Resources/whale_returns.csv\", index_col='Date', parse_dates=True, infer_datetime_format=True)\n",
    "# YOUR CODE HERE\n",
    "whale_returns_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1060, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whale_returns_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls\n",
    "# YOUR CODE HERE\n",
    "whale_null = whale_returns_csv.isnull().sum().sum()\n",
    "whale_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "# YOUR CODE HERE\n",
    "whale_data = whale_returns_csv.dropna()\n",
    "whale_null2 = whale_data.isnull().sum().sum()\n",
    "whale_null2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmic Daily Returns\n",
    "\n",
    "Read the algorithmic daily returns and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading algorithmic returns\n",
    "# YOUR CODE HERE\n",
    "algo_returns_csv = pd.read_csv(\"../Resources/algo_returns.csv\", index_col='Date', parse_dates=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls\n",
    "# YOUR CODE HERE\n",
    "algo_null = algo_returns_csv.isnull().sum().sum()\n",
    "algo_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "# YOUR CODE HERE\n",
    "algo_data = algo_returns_csv.dropna()\n",
    "algo_null2 = algo_data.isnull().sum().sum()\n",
    "algo_null2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 Returns\n",
    "\n",
    "Read the S&P500 Historic Closing Prices and create a new daily returns DataFrame from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading S&P 500 Closing Prices\n",
    "# YOUR CODE HERE\n",
    "sp500_returns_csv = pd.read_csv(\"../Resources/sp500_history.csv\", index_col='Date', parse_dates=True, infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Data Types\n",
    "# YOUR CODE HERE\n",
    "sp500_returns_csv.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Data Types\n",
    "# YOUR CODE HERE\n",
    "sp500_returns_csv['Close'] = sp500_returns_csv['Close'].str.replace('$', '')\n",
    "sp500_returns_csv['Close'] = sp500_returns_csv.Close.astype(float)\n",
    "sp500_returns_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Daily Returns\n",
    "# YOUR CODE HERE\n",
    "sp500_daily = sp500_returns_csv.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "# YOUR CODE HERE\n",
    "sp500_daily = sp500_daily.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Column\n",
    "# YOUR CODE HERE\n",
    "sp500_daily.columns = ['SP500']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Whale, Algorithmic, and S&P 500 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames into a single DataFrame\n",
    "# YOUR CODE HERE\n",
    "combined_df = pd.concat([whale_data, algo_data, sp500_daily], axis=\"columns\", join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Analysis\n",
    "\n",
    "In this section, you will calculate and visualize performance and risk metrics for the portfolios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "Calculate and Plot the daily returns and cumulative returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot daily returns\n",
    "# YOUR CODE HERE\n",
    "combined_df.plot(title=\"Combined Daily Returns\", figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns\n",
    "# YOUR CODE HERE\n",
    "((combined_df + 1).cumprod() - 1).plot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk\n",
    "\n",
    "Determine the _risk_ of each portfolio:\n",
    "\n",
    "1. Create a box plot for each portfolio. \n",
    "2. Calculate the standard deviation for all portfolios\n",
    "4. Determine which portfolios are riskier than the S&P 500\n",
    "5. Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot to visually show risk\n",
    "# YOUR CODE \n",
    "whale_data.plot(kind=\"box\", title=\"Whale Daily Returns\", figsize=(20, 10))\n",
    "algo_data.plot(kind=\"box\", title=\"Algo Daily Returns\", figsize=(20, 10))\n",
    "sp500_daily.plot(kind=\"box\", title=\"SP500 Daily Returns\", figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Standard Deviations\n",
    "# Calculate the standard deviation for each portfolio. Which portfolios are riskier than the S&P 500?\n",
    "# YOUR CODE HERE\n",
    "whale_std  = whale_data.std()\n",
    "algo_std = algo_data.std()\n",
    "sp500_std = sp500_daily.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whale_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which portfolios are riskier than the S&P 500\n",
    "# YOUR CODE HERE\n",
    "portfolio_std = pd.DataFrame({\n",
    "    \"Whale\": whale_std,\n",
    "    \"Algo\": algo_std,\n",
    "    \"SP 500\": sp500_std\n",
    "})\n",
    "\n",
    "portfolio_std.plot.hist(stacked=True, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Whale Portfolio is the riskiest of the 3 because it has the higher standard spread of standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annualized standard deviation (252 trading days)\n",
    "# YOUR CODE HERE\n",
    "annualized_whale_std = whale_std * np.sqrt(252)\n",
    "annualized_algo_std = algo_std * np.sqrt(252)\n",
    "annualized_sp500_std = sp500_std * np.sqrt(252)\n",
    "annualized_portfolio_std = portfolio_std * np.sqrt(252)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annualized_sp500_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Statistics\n",
    "\n",
    "Risk changes over time. Analyze the rolling statistics for Risk and Beta. \n",
    "\n",
    "1. Calculate and plot the rolling standard deviation for the S&PP 500 using a 21 day window\n",
    "2. Calcualte the correlation between each stock to determine which portfolios may mimick the S&P 500\n",
    "2. Calculate and plot a 60 day Beta for Berkshire Hathaway Inc compared to the S&&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the rolling standard deviation for the S&PP 500 using a 21 day window\n",
    "# YOUR CODE HERE\n",
    "sp500_daily.rolling(window=21).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation\n",
    "# YOUR CODE HERE\n",
    "correlation = combined_df.corr()\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Beta for a single portfolio compared to the total market (S&P 500)\n",
    "# YOUR CODE HERE\n",
    "#variance\n",
    "variance = combined_df['SP500'].var()\n",
    "\n",
    "#Soros\n",
    "soros_covariance = combined_df['SOROS FUND MANAGEMENT LLC'].cov(combined_df['SP500'])\n",
    "soros_beta = soros_covariance / variance\n",
    "\n",
    "#Paulson\n",
    "paulson_covariance = combined_df['PAULSON & CO.INC. '].cov(combined_df['SP500'])\n",
    "paulson_beta = paulson_covariance / variance\n",
    "\n",
    "#Tiger\n",
    "tiger_covariance = combined_df['TIGER GLOBAL MANAGEMENT LLC'].cov(combined_df['SP500'])\n",
    "tiger_beta = tiger_covariance / variance\n",
    "\n",
    "#Berkshire\n",
    "berkshire_covariance = combined_df['BERKSHIRE HATHAWAY INC'].cov(combined_df['SP500'])\n",
    "berkshire_beta = berkshire_covariance / variance\n",
    "\n",
    "#covariance = daily_returns['AMZN'].cov(daily_returns['S&P 500'])\n",
    "#covariance\n",
    "\n",
    "#variance = daily_returns['S&P 500'].var()\n",
    "#variance\n",
    "\n",
    "#amzn_beta = covariance / variance\n",
    "#amzn_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'{variance}')\n",
    "#print(f\"{soros_covariance}, {paulson_covariance}, {tiger_covariance}, {berkshire_covariance}\")\n",
    "print(f'The betas for the Whale Portfolio are as follows: \\nSoros Fund Management LLC: {soros_beta},\\nPaulson & Co. Inc: {paulson_beta} \\nTiger Global Management LLC: {tiger_beta} \\nBerkshire Hathaway Inc: {berkshire_beta}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Exponentially Weighted Average \n",
    "\n",
    "An alternative way to calculate a rollwing window is to take the exponentially weighted moving average. This is like a moving window average, but it assigns greater importance to more recent observations. Try calculating the `ewm` with a 21 day half-life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (OPTIONAL) YOUR CODE HERE\n",
    "exponentially_weighted_average = combined_df.ewm(halflife=21).mean()\n",
    "exponentially_weighted_average.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpe Ratios\n",
    "In reality, investment managers and thier institutional investors look at the ratio of return-to-risk, and not just returns alone. (After all, if you could invest in one of two portfolios, each offered the same 10% return, yet one offered lower risk, you'd take that one, right?)\n",
    "\n",
    "Calculate and plot the annualized Sharpe ratios for all portfolios to determine which portfolio has the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annualzied Sharpe Ratios\n",
    "# YOUR CODE HERE\n",
    "sharpe_ratios = (combined_df.mean() * 252) / (combined_df.std() * np.sqrt(252))\n",
    "sharpe_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " plot() these sharpe ratios using a barplot.\n",
    " On the basis of this performance metric, do our algo strategies outperform both 'the market' and the whales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "# YOUR CODE HERE\n",
    "sharpe_ratios.plot(kind=\"bar\", title=\"Sharpe Ratios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Returns\n",
    "\n",
    "In this section, you will build your own portfolio of stocks, calculate the returns, and compare the results to the Whale Portfolios and the S&P 500. \n",
    "\n",
    "1. Choose 3-5 custom stocks with at last 1 year's worth of historic prices and create a DataFrame of the closing prices and dates for each stock.\n",
    "2. Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock\n",
    "3. Join your portfolio returns to the DataFrame that contains all of the portfolio returns\n",
    "4. Re-run the performance and risk analysis with your portfolio to see how it compares to the others\n",
    "5. Include correlation analysis to determine which stocks (if any) are correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose 3-5 custom stocks with at last 1 year's worth of historic prices and create a DataFrame of the closing prices and dates for each stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install yfinance package.\n",
    "!pip install yfinance\n",
    "     \n",
    "# Import yfinance\n",
    "import yfinance as yf  \n",
    "     \n",
    "# Get the data for the stock Apple by specifying the stock ticker, start date, and end date\n",
    "\n",
    "     \n",
    "# Plot the close prices\n",
    "#import matplotlib.pyplot as plt\n",
    "#data.Close.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "beginning_date = today + dt.timedelta(-365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first stock\n",
    "# YOUR CODE HERE\n",
    "pru_data = yf.download('PRU', beginning_date, today, parse_dates=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the second stock\n",
    "# YOUR CODE HERE\n",
    "voo_data = yf.download('VOO', beginning_date, today, parse_dates=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the third stock\n",
    "# YOUR CODE HERE\n",
    "axp_data = yf.download('AXP', beginning_date, today, parse_dates=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the third stock\n",
    "# YOUR CODE HERE\n",
    "spx_data = yf.download('^GSPC', beginning_date, today, parse_dates=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pru_data.drop(columns =['Open','High','Low','Adj Close','Volume'] , inplace=True)\n",
    "pru_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voo_data.drop(columns =['Open','High','Low','Adj Close','Volume'] , inplace=True)\n",
    "voo_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axp_data.drop(columns =['Open','High','Low','Adj Close','Volume'] , inplace=True)\n",
    "axp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_data.drop(columns =['Open','High','Low','Adj Close','Volume'] , inplace=True)\n",
    "spx_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all stocks into a single DataFrame\n",
    "# YOUR CODE HERE\n",
    "portfolio_df = pd.concat([pru_data, voo_data, axp_data], axis=\"columns\", join=\"inner\")\n",
    "portfolio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Did not reset because the date time came in from my data pull from yfianance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the Data so that the stock tickers are the columns, the dates are the index, and the \n",
    "# values are the closing prices\n",
    "# YOUR CODE HERE\n",
    "portfolio_df.columns=['PRU','VOO',\"AXP\"]\n",
    "portfolio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Nulls\n",
    "# YOUR CODE HERE\n",
    "portfolio_df.dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted portfolio returns\n",
    "weights = [1/3, 1/3, 1/3]\n",
    "# YOUR CODE HERE\n",
    "daily_returns = portfolio_df.pct_change()\n",
    "portfolio_returns = daily_returns.dot(weights)\n",
    "portfolio_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join your portfolio returns to the DataFrame that contains all of the portfolio returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "daily_returns['Returns'] = portfolio_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only compare dates where the new, custom portfolio has dates\n",
    "# YOUR CODE HERE\n",
    "daily_returns.dropna(inplace=True)\n",
    "daily_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run the performance and risk analysis with your portfolio to see how it compares to the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk\n",
    "# YOUR CODE HERE\n",
    "\n",
    "portfolio_std = portfolio_df.std()\n",
    "portfolio_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_std_mapped = pd.DataFrame({\n",
    "    \"PRU\": portfolio_df['PRU'].std(),\n",
    "    \"VOO\": portfolio_df['VOO'].std(),\n",
    "    \"AXP\": portfolio_df['AXP'].std(),\n",
    "    },\n",
    "    index=[0])\n",
    "\n",
    "portfolio_std_mapped.plot.hist(stacked=True, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling\n",
    "# YOUR CODE HERE\n",
    "portfolio_df.rolling(window=1).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns['SPX'] = spx_data.pct_change()\n",
    "daily_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta\n",
    "# YOUR CODE HERE\n",
    "variance = daily_returns['SPX'].var()\n",
    "\n",
    "\n",
    "#PRU\n",
    "pru_covariance = daily_returns['PRU'].cov(daily_returns['SPX'])\n",
    "pru_beta = pru_covariance / variance\n",
    "\n",
    "#VOO\n",
    "voo_covariance = daily_returns['VOO'].cov(daily_returns['SPX'])\n",
    "voo_beta = voo_covariance / variance\n",
    "\n",
    "#AXP\n",
    "axp_covariance = daily_returns['AXP'].cov(daily_returns['SPX'])\n",
    "axp_beta = axp_covariance / variance\n",
    "\n",
    "\n",
    "#covariance = daily_returns['AMZN'].cov(daily_returns['S&P 500'])\n",
    "#covariance\n",
    "\n",
    "#variance = daily_returns['S&P 500'].var()\n",
    "#variance\n",
    "\n",
    "#amzn_beta = covariance / variance\n",
    "#amzn_beta\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annualzied Sharpe Ratios\n",
    "# YOUR CODE HERE\n",
    "sharpe_ratios = (daily_returns.mean() * 252) / (daily_returns.std() * np.sqrt(252))\n",
    "sharpe_ratios.drop(['Returns','SPX'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "# YOUR CODE HERE\n",
    "sharpe_ratios.plot.bar(title='Sharpe Ratios')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include correlation analysis to determine which stocks (if any) are correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "correlation = portfolio_df.corr()\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There might be some coorelation between VOO and AXP but overall none of the 3 stocks I picked have any strong correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "nteract": {
   "version": "0.12.3"
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
